import streamlit as st
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import time
import pandas as pd
import base64
import requests
from bs4 import BeautifulSoup

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë”ì¿  í¬ë¡¤ëŸ¬", page_icon="ğŸ”")
st.title("ë”ì¿ (theqoo) í¬ë¡¤ëŸ¬")
st.markdown("theqoo.netì—ì„œ íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²Œì‹œë¬¼ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("ê²€ìƒ‰ ì„¤ì •")
    pages_to_crawl = st.slider("í¬ë¡¤ë§í•  í˜ì´ì§€ ìˆ˜", min_value=1, max_value=10, value=5)
    
    # í‚¤ì›Œë“œ ì…ë ¥
    default_keywords = "ìœ ì‹¬, SKT"
    keywords_input = st.text_input("ê²€ìƒ‰ í‚¤ì›Œë“œ (ì‰¼í‘œë¡œ êµ¬ë¶„)", value=default_keywords)
    keywords = [k.strip() for k in keywords_input.split(",")]
    
    # ì¶”ê°€ ì„¤ì •
    show_links = st.checkbox("ë§í¬ í‘œì‹œ", value=True)

# í¬ë¡¤ë§ ê¸°ëŠ¥ ì •ì˜
def crawl_theqoo(pages_to_crawl, keywords):
    filtered_posts = []
    
    # ì§„í–‰ìƒí™© í‘œì‹œ
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        # í¬ë¡¬ ì˜µì…˜ ì„¤ì •
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        
        status_text.text("ë¸Œë¼ìš°ì €ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘...")
        driver = webdriver.Chrome(options=chrome_options)
        
        # ì„¤ì •
        base_url = 'https://theqoo.net/hot?page='
        
        for page_idx, page in enumerate(range(1, pages_to_crawl + 1)):
            status_text.text(f"í˜ì´ì§€ {page}/{pages_to_crawl} í¬ë¡¤ë§ ì¤‘...")
            progress_bar.progress((page_idx) / pages_to_crawl)
            
            url = base_url + str(page)
            driver.get(url)
            time.sleep(2)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
            
            posts = driver.find_elements(By.CSS_SELECTOR, 'td.title a')
            
            for post in posts:
                title = post.text.strip()
                link = post.get_attribute('href')
                
                if any(keyword in title for keyword in keywords):
                    filtered_posts.append({'title': title, 'link': link})
            
            time.sleep(1)  # ì„œë²„ ë¶€ë‹´ ì¤„ì´ê¸°
        
        # ë¸Œë¼ìš°ì € ì¢…ë£Œ
        driver.quit()
        progress_bar.progress(1.0)
        status_text.text("í¬ë¡¤ë§ ì™„ë£Œ!")
        
        return filtered_posts
    
    except Exception as e:
        st.error(f"í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return []

# CSV ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥
def get_csv_download_link(df):
    csv = df.to_csv(index=False)
    b64 = base64.b64encode(csv.encode()).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="theqoo_results.csv">CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ</a>'
    return href

# ë©”ì¸ ë¡œì§
if st.button("í¬ë¡¤ë§ ì‹œì‘"):
    st.subheader("í¬ë¡¤ë§ ìƒíƒœ")
    
    # í¬ë¡¤ë§ ì‹¤í–‰
    filtered_posts = crawl_theqoo(pages_to_crawl, keywords)
    
    # ê²°ê³¼ í‘œì‹œ
    if filtered_posts:
        st.subheader(f"ê²€ìƒ‰ ê²°ê³¼ ({len(filtered_posts)}ê°œ)")
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df = pd.DataFrame(filtered_posts)
        
        # ê²°ê³¼ í…Œì´ë¸” í‘œì‹œ
        if show_links:
            # ë§í¬ë¥¼ í´ë¦­í•  ìˆ˜ ìˆê²Œ ë§Œë“¤ê¸°
            df_display = df.copy()
            df_display['link'] = df_display['link'].apply(lambda x: f'<a href="{x}" target="_blank">{x}</a>')
            st.write(df_display.to_html(escape=False), unsafe_allow_html=True)
        else:
            st.dataframe(df)
        
        # CSV ë‹¤ìš´ë¡œë“œ ë§í¬ ì œê³µ
        st.markdown(get_csv_download_link(df), unsafe_allow_html=True)
    else:
        st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")

# ì£¼ì˜ì‚¬í•­
st.markdown("---")
st.caption("ì£¼ì˜: ì›¹ í¬ë¡¤ë§ì€ ëŒ€ìƒ ì›¹ì‚¬ì´íŠ¸ì˜ ì´ìš©ì•½ê´€ì„ ì¤€ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤. ê°œì¸ì ì¸ ìš©ë„ë¡œë§Œ ì‚¬ìš©í•˜ì„¸ìš”.") 
